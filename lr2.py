# -*- coding: utf-8 -*-
"""LR2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f1SRlA3s_GiX-LhIWeGm9L6hLeE63_aQ
"""

#import modules

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

#import the student_scores data set ans use df head to view data

df=pd.read_csv("student_scores.csv")

df.head()

#Now we will info to tell us about the data

df.info()

#it will gives us information on the columns and rows in the dataset

#We will use describe to convert rows into statistics

df.describe()

#This helpd us get an overall mathmatical depiction of our dataset in tableuer form

#Now lets run a scatter plot comparing the data points we want to use
#We want x= Hours and y= Scores
df.plot(x='Hours',y='Scores',style='o')
plt.xlabel("Hours")
plt.ylabel("Scores")
plt.ticklabel_format(axis="y", style="plain")
plt.show()

#The image below shows us the correlation of our data

#From face value we can see the data comparision is linear

#Our independant value that we will measure Score against will be Hours
#So we will put that in the X variable which will be used as our X-Axis
X = df[['Hours']]

#We put X into a dataframe so we want to check the type to make sure
type(X)
#it is a dataframe

#Our dependant value or the predictor value will be Scores
#So we will put that in the Y variable which will be used as our Y-Axis
y=df['Scores']

#Now we are going to check the type to make sure it is a series
type(y)
#The type is a series

#import train_test_split from scikit learn
from sklearn.model_selection import train_test_split

#Now we need to split and train our data
#Train test split is used to evaluate the performance of a Machine Leaning model
#The Train label for X & y is used for training the model with the correct inputs and labels we are looking for
#While the test is going to be another aggregated dataset that will be filtered through the model and it will make predictions on that data
#we want the model to be as robust as possible
X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.25,random_state=0)

#import Linear Regression model from scikit learn
from sklearn.linear_model import LinearRegression

#Here we are going to bring in our linear Regression model and start fitting the data and training the model
#Linear regression model is used when you want to predict an out come on data
#with simple linear regression you are comparing two data point(X,y) and it will predict the values for you
lr = LinearRegression()
lr.fit(X_train,y_train)

#The .predict() helps us predict the values that were on the trained model
y_pred = lr.predict(X_test)

#plot actual vs predicted
#Here we are comparing the test data set(Which is the correct data and labels) and the prediction dataset for price

c = [i for i in range (1,len(y_test)+1,1)]

plt.plot(c,y_test,color='r',linestyle='-')
plt.plot(c,y_pred,color='b',linestyle='-')
plt.xlabel('Scores')
plt.ylabel('index')
plt.title('Prediction')
plt.ticklabel_format(axis="y", style="plain")
plt.show()

#Our prediction data is in blue
#Our historical or training set is in red

#you can see that the values predicted seem to be right inline with the historical values
#This is a good sign!

# plotting the error
#Here we are plotting the errorr values that were in the predicted set
c = [i for i in range(1,len(y_test)+1,1)]
plt.plot(c,y_test-y_pred,color='green',linestyle='-')
plt.xlabel('index')
plt.ylabel('Error')
plt.title('Error Value')
plt.ticklabel_format(axis="y", style="plain")
plt.show()

#Accuracy metrics from scikit learn
from sklearn import metrics
#MAE definition:is a measure of the average size of the mistakes in a collection of predictions, without taking their direction into account
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
#MSE: measures how close a regression line is to a set of data points.
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
#is one of the most commonly used measures for evaluating the quality of predictions. It shows how far predictions fall from measured true values
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
print('r square :' , metrics.r2_score(y_test, y_pred))

#r-squared shows how well the data fit the regression model
#a good r-squared values is between 0.50 to 0.99
#This output is above that at a 0.94 that is very good!

# Intercept and coefficient of the line
print('Intercept of the model:',lr.intercept_)
print('Coefficient of the line:',lr.coef_)

# Plot actual and predicted values
plt.figure(figsize=(12,6))
plt.scatter(y_test,y_pred,color='r',linestyle='-')
plt.ticklabel_format(axis="y", style="plain")
plt.ticklabel_format(axis="x", style="plain")
plt.show()

